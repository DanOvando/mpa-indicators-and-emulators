---
title: "How Reliable are Common Empirical Indicators at Measuring MPA Performance?"
author:
  - name: Daniel Ovando
    affiliation:
      - name: Inter-American Tropical Tuna Commission
        department: Ecosystem & Bycatch Group
        id: 1
        address: 8901 La Jolla Shores Drive
        city: La Jolla
        state: CA
        postal-code: 92037
    email: dovando@iattc.org
    attributes:
      equal-contributor: true
      corresponding: true
format:
  html: 
    toc: true
  pdf:
    toc: true
  nature-pdf:
    keep-tex: true
    classoption: [lineno, referee]
    toc: true
    equal-margins: true
bibliography: references.bib
abstract: |
 Something
keywords: [MPA, Simulation Modeling, Model Selection, Conservation Planning, Food Security]
execute: 
  echo: false
  warning: false
---

```{r}
#|label: setup
#|include: false

foos <- list.files(here::here("R"))

purrr::walk(foos, ~ source(here::here("R", .x)))

prep_run(run_name = "indicators_v0.1") # loads packages and creates and returns some global variables for the analysis

# clean up figures generated in the report to ensure that all figures come from a fresh state
paper_figs <- file.path(fig_dir,list.files(fig_dir)[list.files(fig_dir) |> str_detect("fig_")])

unlink(paper_figs)

min_depletion <- 0.00001

tune_grids <- FALSE
```


Need to fix some processing here, the whole "fleets" thing where there are rows for nature and then for individual fleets is messing some stuff up. 

Need to separate out the fleets part, then join the nature part

the solution is to aggreate indicators across fleets, so that you just look at average effort and cpue in total rather than by fleet you dummy

```{r}
#| label: load-results
#| include: false


results <- list.files(results_dir)

results <- results[str_detect(results,"(processed_sims.rds$)|(emulated_experiment_results.rds)|(placement_experiments.rds)|(state_experiments.rds)")]



purrr::walk(results, ~ assign(str_remove_all(.x,"\\.rds$"), read_rds(here(results_dir,.x)), envir = .GlobalEnv))

critter_namer <- function(x){
  
  y <- forcats::fct_recode(x,shark = "carcharhinus amblyrhynchos",grouper = "epinephelus fuscoguttatus",snapper = "lutjanus malabaricus", "deep-snapper" = "pristipomoides filamentosus")
  
}

# process marlin simulations

## get MPA sizes

simple <- simple_state_experiments |>
  select(state_id, depletion) |>
  unnest(cols = depletion) |>
  mutate(difficulty = "simple")

medium <- medium_state_experiments |>
  select(state_id, depletion) |>
  unnest(cols = depletion) |>
  mutate(difficulty = "medium")

complex <- complex_state_experiments |>
  select(state_id, depletion) |>
  unnest(cols = depletion) |>
  mutate(difficulty = "complex")

state_depletions <- simple |>
  bind_rows(medium) |>
  bind_rows(complex) |>
  mutate(state_id = glue("{difficulty}_{state_id}"))
  
valid_state_depletions <- state_depletions |>
  filter(depletion >= min_depletion)


simple <- simple_processed_sims$mpa_outcomes |> 
  mutate(difficulty = "simple")

medium <- medium_processed_sims$mpa_outcomes |> 
  mutate(difficulty = "medium")

complex <- complex_processed_sims$mpa_outcomes |> 
  mutate(difficulty = "complex")

# results of all marlin simulations
inds_and_outs <- simple |> 
  bind_rows(medium) |> 
  bind_rows(complex) |> 
  mutate(state_id = glue("{difficulty}_{state_id}")) |> 
  mutate(id = glue("{difficulty}-{id}")) |> 
  mutate(prop_mpa = as_factor(prop_mpa)) |> 
  mutate(difficulty = fct_relevel(difficulty,"simple", "medium"))

rm(list = c("simple", "medium", "complex"))


```

## Introduction

Two key questions

1.  Are MPA outcomes variable enough to provide a need for indicators

2.  Which indicators can reliably track that viability if so?

Things change for lots of reasons in ecological systems. These changes are often correlated in space and time... blah

## Methods

### Empirical Indicators

A range of indicators...[@harford2021]

"It uses the means of biomass (for targeted and nontargeted fish species)... inside and outside of SMRs across the 2019-20 sampling period as a measure of effect size â€“ that is, an MPA effect."

@caselle2022

#### Response Ratios

Response ratios

$$
log(B) \sim N(MPA,\sigma_{obs})
$$

This is analogous to

$$
log \left(\frac{B_{protected}}{B_{reference}}  \right) = log(B_{protected}) - log(B_{reference})
$$

@lester2009

#### Mean Length

$$
log(L) \sim N(MPA,\sigma)
$$

@lester2009

### Slope over Time

Differences in trends of the response ratio post-implementation @caselle2022

$$
log(B_{t,s}) \sim N(Y_t + T_s + Y_tT_s,\sigma)
$$

#### Gradients

$\delta$

```{r}
alpha = 1

beta <- 1

delta <- -2

int <- 0

x <- seq(-100,100)

y <- alpha / (1 + beta *(exp(delta * x))) + int

plot(x,y)
```

@methratta2020

@halpern2009

@medoff2022

"The expectation that spillover from marine reserves will produce abundance gradients with distance from the reserve, with a shape that depends on species mobility and catch rates, was first described over a decade ago (Rakitin & Kramer 1996) and later refined and modelled (Kaunda-Arara & Rose 2004; Goni et al. 2006)." [@halpern2009]

Sigh. You need to come up with a new metric here that accounts for non-extinction outside.

Come back to this.

Basically, add in intercept, and then the spillover distance is the minimum distance at which the value of the non-intercept part of the curve is zero.

@halpern2009 defined two metrics for estimating spillover distance; the distance at which biomass density was 5% of the maximum observed biomass density inside or outside of the MPA, and the distance at which biomass density was 5% of the range, where range is calculated as the average of the two points furthest from the reserve border and the two points furthest inside the reserve, after fitting a smoother to the density as a function of distance relationship

However, this method makes the assumption that biomass density goes to 0 at some distance from the reserve.

OK, so you're going to do a modified halpern as a starting place

Estimate the same thing but with an intercept, such that the logistic thing is additive to a baseline level, and then calculate the distance at which the additive component of the MPA becomes zero. When there is no effect, or when the MPA has massive but diffuse effects, this distance will be 0, etc.

Or, a simpler and more generalizable approach would be to split outside distance into "near" vs "far", and then see if a given outcome is higher near relative to far. Makes life a lot simpler of not having to consider non-linear functions etc. The downside is it makes it tough to say what is "near" what is "far". Simplest approach would be to say the bottom 25%th percentile of distance is near, the top is far, and go with that.

The nice thing about all this is that it's about seeing if something is or isn't useful, so if that ends up being useful, then great!

### 

## Results

### How Variable are MPA Effects?

```{r}

  # mutate(percent_mpa_effect = pmin(100, 100 * percent_mpa_effect))

fleet_outcomes <- inds_and_outs |>
  select(
    percent_mpa_effect,
    fleet,
    state_id,
    placement_id,
    critter,
    prop_mpa,
    name,
    f_v_m,
    difficulty
  ) |>
  filter(fleet != "nature") |>
  pivot_wider(names_from = "name", values_from = "percent_mpa_effect")

nature_outcomes <- inds_and_outs |>
  filter(fleet == "nature") |>
  select(ends_with("id"),
         critter,
         prop_mpa,
         name,
         percent_mpa_effect,
         difficulty) |>
  pivot_wider(names_from = "name", values_from = "percent_mpa_effect")

mpa_outcomes <- fleet_outcomes |>
  left_join(nature_outcomes,
            by = join_by(state_id, placement_id, critter, prop_mpa, difficulty)) |>
  mutate(numeric_prop_mpa = as.numeric(as.character(prop_mpa)))

  
  quad_labels <- data.frame(
    x = c(50, 50, -24, -24),
    y = c(50, -50, 50, -50),
    label = c("Win-Win", "Win-Lose", "Lose-Win", "Lose-Lose")
  )
  thirty_protected_plot <- mpa_outcomes |>
    # filter(between(numeric_prop_mpa, 0.2, 0.4)) |>
    ggplot(aes(biomass, catch)) +
    geom_vline(xintercept = 0, color = "black") +
    geom_hline(yintercept = 0, color = "black") +
    geom_jitter(aes(color = f_v_m), alpha = 0.25, size = 3) +
    # geom_text(
    #   data = quad_labels,
    #   aes(x, y, label = label),
    #   size = 6,
    #   color = "red"
    # ) +
    scale_color_viridis_c(
      "BAU Fishing Mortality",
      breaks = c(0, .5),
      labels = c("Low", "High"),
      limits = c(0, .5),
      option = "plasma",
      guide = guide_colorbar(
        frame.colour = "black",
        ticks.colour = "black",
        barwidth =  unit(11, "lines")
      )
    )  +
    scale_x_continuous(name = "X Change in Species Biomass",
                       oob = squish,
                       limits = c(NA, 1)) +
    scale_y_continuous(name = "X Change in Species Catch",
                       oob = squish,
                       limits = c(NA, 1)) +
    theme(legend.position = "bottom") +
    labs(caption = "20-40% of area in MPA") + 
    facet_wrap(~difficulty)
  
  
  # thirty_protected_plot <- ggMarginal(thirty_protected_plot,
  #                                     type = "histogram",
  #                                     fill = "steelblue")
  
  thirty_protected_plot
```

### Indicator Performance

The idea: let's break this into outcomes (population change, inside change, outside change, food change, quadrant) and have a subsection for each of those. For each section, you'll identify a top performer, and then have a table or figure summarizing for each thing the best indicator and its relative performance. 

So how are you going to judge performance? I guess error and bias for the quantitative sections, and then classification accuracy for the quadrant? RMSE and MAE, accuracy

```{r}


# View(head(inds_and_outs))

indicators <- inds_and_outs |>
  select(critter,
         prop_mpa,
         state_id,
         placement_id,
         difficulty,
         prop_mpa,
         starts_with("ind")) |>
  pivot_longer(starts_with("ind_"),
               names_to = "indicator",
               values_to = "indicator_value") |>
  filter(!is.na(indicator_value))

outcomes <- inds_and_outs |> 
  select(state_id, placement_id,critter,fleet,prop_mpa, difficulty, percent_mpa_effect, name)

quadrant_outcomes <- fleet_outcomes |>
  select(state_id, prop_mpa, placement_id, critter, fleet, difficulty, catch) |>
  left_join(nature_outcomes |> select(state_id, prop_mpa, placement_id, critter, biomass, difficulty),by = join_by(state_id, prop_mpa, placement_id, critter, difficulty)) |>
  pivot_longer(c(catch,biomass)) |>
  mutate(tag = paste(
    name,
    case_when(value > 0.05 ~ "positive", value < -0.05 ~ "negative", .default = "unaffected"),
    sep = ":"
  )) |>
  select(-value) |>
  pivot_wider(names_from = name, values_from = tag) |>
  mutate(quadrant = paste(catch, biomass, sep = " & ")) |>
  left_join(
    inds_and_outs |>
  select(critter,
         prop_mpa,
         state_id,
         placement_id,
         difficulty,
         prop_mpa,
         starts_with("ind")),
    by = c(
      "critter",
      "state_id",
      "placement_id",
      "prop_mpa",
      "difficulty"
    ),
    relationship = "many-to-many"
  )


quadrant_outcomes |> 
  ggplot(aes(quadrant)) + 
  geom_bar() + 
  coord_flip()

comparison <- outcomes |> 
  left_join(indicators, by = c("critter", "state_id", "placement_id", "prop_mpa", "difficulty"), relationship = "many-to-many") |> 
  mutate(percent_mpa = as.numeric(as.character(prop_mpa)))

head(comparison)


known_habitat_plot <- comparison |> 
  filter(percent_mpa <= 0.1) |> 
  filter(name %in% c("biomass", "catch", "revenue"),
         !str_detect(indicator,"_raw")) |> 
  mutate(indicator = str_remove_all(indicator, "ind_")) |> 
  ggplot(aes(indicator_value, percent_mpa_effect)) + 
  geom_point(alpha = 0.2) + 
  geom_smooth(method = "lm") +
  facet_grid(name ~ indicator, scales = "free") + 
  scale_y_continuous(limits = c(NA,2), oob = squish) + 
  scale_fill_viridis_b() + 
  labs(title = "Habitat known")

known_habitat_plot

unknown_habitat_plot <- comparison |> 
  # filter(prop_mpa < 0.4) |> 
  filter(name %in% c("biomass", "catch", "revenue"),
         str_detect(indicator,"_raw")) |> 
  mutate(indicator = str_remove_all(indicator, "ind_")) |> 
  ggplot(aes(indicator_value, percent_mpa_effect)) + 
  geom_point(alpha = 0.2) + 
  geom_smooth(method = "lm") +
  facet_grid(name ~ indicator, scales = "free") + 
  scale_y_continuous(limits = c(NA,2), oob = squish) + 
  scale_fill_viridis_b() + 
  labs(title = "Habitat unknown")

unknown_habitat_plot

```

```{r}

measure_performance <- function(x){
  
  augx <- broom::augment(x)
  
  # plot(augx$.fitted, augx$percent_mpa_effect)
  # browser()
  out <- data.frame(rmse = yardstick::rmse_vec(augx$percent_mpa_effect, augx$.fitted),
                    bias = mean(augx$percent_mpa_effect- augx$.fitted))
  
}

indicator_performance <- comparison |>
  filter(is.finite(percent_mpa_effect), is.finite(indicator_value)) |> 
  filter(!is.na(indicator)) |> 
  group_by(name, indicator, difficulty) |>
  nest() |>
  mutate(model = map(data, ~ lm(
    percent_mpa_effect ~ indicator_value, data = .x
  ))) |> 
  mutate(model_summary = map(model, broom::glance)) |> 
  mutate(model_performance = map(model, measure_performance)) |> 
  unnest(cols = c(model_summary,model_performance))

  
indicator_performance |> 
  mutate(raw = str_detect(indicator, "_raw")) |> 
  ggplot(aes(adj.r.squared, fill = raw)) + 
  geom_dotplot() + 
  facet_grid(indicator~difficulty, scales = "free_y")


indicator_performance |> 
  mutate(raw = str_detect(indicator, "_raw")) |> 
  ggplot(aes(rmse, fill = raw)) + 
  geom_dotplot() + 
  facet_grid(indicator~difficulty, scales = "free_y") + 
  scale_x_continuous(limits = c(NA,2), oob = squish)



indicator_performance |> 
  mutate(raw = str_detect(indicator, "_raw")) |> 
  ggplot(aes(bias, fill = raw)) + 
  geom_dotplot() + 
  facet_grid(indicator~difficulty, scales = "free_y") 





```

### Discussion

Note that this is all assuming equilibrium! 

Just as a quota for one species can have unintended consequences on another, so can MPAs. 

Let us be clear. THe simulation results presented here indicate that clearly MPAs are capable of benefiting biomass and catch. However, they are also capable of harming both.

We implement size limits all the time without needing complex causal inference. Part of the reason for that is that it's a more direct lever, but still. But, if the movement of the coming yeasr was "No Undersized by 2035", resulting in a massive global investment in the design and roll of out size limit programs, a deeper look at measuring the prformance of size limits might be warranted 

@halpern2004

@franceschini2024
